{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10257261,"sourceType":"datasetVersion","datasetId":6345245}],"dockerImageVersionId":30824,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rasterio\nfrom pathlib import Path\nimport pandas as pd \nimport numpy  as np \nimport json\nfrom collections import Counter\nfrom shapely.wkt import loads\nfrom shapely.geometry import Polygon, box\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.mask import mask\nfrom rasterio.plot import reshape_as_raster\nfrom rasterio.transform import from_bounds\nfrom tqdm.notebook import tqdm\n\n# Visulazation  \nimport  matplotlib.pyplot as plt \nfrom PIL import Image, ImageDraw\n\n\n\n# PyTorch and computer vision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection import maskrcnn_resnet50_fpn\nfrom torchvision.models.detection.backbone_utils import resnet_fpn_backbone\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNN, MaskRCNNPredictor\nfrom torchvision.models.detection.roi_heads import RoIHeads\nfrom torchvision.transforms import functional as F\n##########  https://www.kaggle.com/muhammadqasimshabbir/datasets\n########   get training data  from  myprofile \n\n# Load test image coords and image paths\ntest_coords = pd.read_csv(\"/kaggle/input/testdatakuyeseraaidisasterdamageanddisplacement/test_image_coords.csv\")\ntest_pre_df = pd.Series(\n    [\n        x\n        for x in Path(\"/kaggle/input/testdatakuyeseraaidisasterdamageanddisplacement/test_images/Images/\").glob(\"*.tif\")\n        if x.parts[-1].split(\".\")[0].split(\"_\")[-2] == \"pre\"\n    ]\n).to_frame(name=\"pre_image_path\")\ntest_post_df = pd.Series(\n    [\n        x\n        for x in Path(\"/kaggle/input/testdatakuyeseraaidisasterdamageanddisplacement/test_images/Images/\").glob(\"*.tif\")\n        if x.parts[-1].split(\".\")[0].split(\"_\")[-2] == \"post\"\n    ]\n).to_frame(name=\"post_image_path\")\n\ntest_pre_df[\"id\"] = [\n    \"_\".join(x.parts[-1].split(\".\")[0].split(\"_\")[:-2])\n    for x in test_pre_df.pre_image_path\n]\ntest_post_df[\"id\"] = [\n    \"_\".join(x.parts[-1].split(\".\")[0].split(\"_\")[:-2])\n    for x in test_post_df.post_image_path\n]\n\ntest_df = test_pre_df.merge(test_post_df, how=\"left\", on=\"id\")\ntest_df = test_coords.merge(test_df, how=\"left\", on=\"id\")\ntest_df[\"flood_name\"] = [\"_\".join(x.split(\"_\")[:-1]) for x in test_df.id]\n\n\n# Extract and add lat and lon bounds - to be used in downloading data from aws\ndef parse_coords(coord_str):\n    # Remove parentheses\n    coord_str = coord_str.strip(\"()\")\n    # Split by the semicolon\n    lat_str, lon_str = coord_str.split(\";\")\n    # Convert to float\n    lat = float(lat_str)\n    lon = float(lon_str)\n    return lat, lon\n\n\n# Add columns for min/max lat/lon\ntest_df[\"post_min_lon\"] = None\ntest_df[\"post_max_lon\"] = None\ntest_df[\"post_min_lat\"] = None\ntest_df[\"post_max_lat\"] = None\n\nfor idx, row in test_df.iterrows():\n    # Parse all four corner coordinates\n    corners = [\n        parse_coords(row[\"pre_top_left\"]),\n        parse_coords(row[\"pre_top_right\"]),\n        parse_coords(row[\"pre_bottom_right\"]),\n        parse_coords(row[\"pre_bottom_left\"]),\n    ]\n\n    # Extract all latitudes and longitudes into separate lists\n    lats = [c[0] for c in corners]\n    lons = [c[1] for c in corners]\n\n    # Compute min/max latitude and longitude\n    min_lat = min(lats)\n    max_lat = max(lats)\n    min_lon = min(lons)\n    max_lon = max(lons)\n\n    # Assign to DataFrame\n    test_df.at[idx, \"post_min_lat\"] = min_lat\n    test_df.at[idx, \"post_max_lat\"] = max_lat\n    test_df.at[idx, \"post_min_lon\"] = min_lon\n    test_df.at[idx, \"post_max_lon\"] = max_lon\n\n\n\n\n\n\n\n########## YOU CAN USE TIER1 AND TIER3 WHICH PART OF DATA YOU CAN USE YOU WANT TO USE\n########## THEY ARE PRESENT profile   https://www.kaggle.com/muhammadqasimshabbir/datasets\ndfs = []\nfrom pathlib import Path\nimport pandas as pd\nimage_dir = Path(\"/kaggle/input/hold-xview-geotiffdata/hold/images/\")\nimage_paths = list(image_dir.rglob(\"*.tif\"))\nimages_df = pd.DataFrame(image_paths, columns=[\"image_path\"])\n\nimages_df[\"id\"] = [\n        \"_\".join(x.parts[-1].split(\".\")[0].split(\"_\")[:-2])\n        for x in images_df.image_path\n    ]\nimages_df[\"pre_post\"] = [\n        x.parts[-1].split(\".\")[0].split(\"_\")[-2] for x in images_df.image_path\n    ]\n\n\n\nlabel_dir = Path(\"/kaggle/input/hold-xview-geotiffdata/hold/labels/\")\nlabel_paths = list(label_dir.rglob(\"*.json\"))\nlabels_df = pd.DataFrame(label_paths, columns=[\"label_path\"])\n\nlabels_df[\"id\"] = [\n        \"_\".join(x.parts[-1].split(\".\")[0].split(\"_\")[:-2])\n        for x in labels_df.label_path\n    ]\nlabels_df[\"pre_post\"] = [\n        x.parts[-1].split(\".\")[0].split(\"_\")[-2] for x in labels_df.label_path\n    ]\n\nmerged_df = images_df.merge(labels_df, how=\"left\", on=[\"id\", \"pre_post\"])\nmerged_df = merged_df[[\"id\", \"pre_post\", \"image_path\", \"label_path\"]]\n# merged_df[\"dataset_type\"] = dataset_path\n\npre_df = merged_df[merged_df.pre_post == \"pre\"]\npost_df = merged_df[merged_df.pre_post == \"post\"]\n\npre_df.columns = [f\"pre_{x.replace('-', '_')}\" for x in pre_df.columns]\npre_df = pre_df.drop([\"pre_pre_post\"], axis=1)\npre_df = pre_df.rename(columns={\"pre_id\": \"id\"})\n\npost_df.columns = [f\"post_{x.replace('-', '_')}\" for x in post_df.columns]\npost_df = post_df.drop([\"post_pre_post\"], axis=1)\npost_df = post_df.rename(\n        columns={\"post_id\": \"id\"}\n    )\n\nmerged_df = pre_df.merge(post_df, how=\"left\", on=[\"id\"])\n\ndfs.append(merged_df)\n\ndf = pd.concat(dfs, ignore_index=True)\ndf[\"flood_name\"] = [\"_\".join(x.split(\"_\")[:-1]) for x in df.id]\n# test_df.head()\ndf.head()\n\n\n\ndef get_subtype_counts(label_path):\n    with open(label_path, \"r\") as file:\n        label_data = json.load(file)\n\n    subtypes = [\n        building[\"properties\"][\"subtype\"] for building in label_data[\"features\"][\"xy\"]\n    ]\n    return Counter(subtypes)\n\n\n# Process each label_path and aggregate counts\nall_counts = []\nfor label_path in df[\"post_label_path\"]:\n    subtype_counts = get_subtype_counts(label_path)\n    all_counts.append(subtype_counts)\n\n# Convert counts to DataFrame and combine with original DataFrame\ncounts_df = (\n    pd.DataFrame(all_counts).fillna(0).astype(int)\n)  # Fill NaN with 0 and cast to int\ndf = pd.concat([df, counts_df], axis=1)\n\n# Drop un-classified, as the main target categories include no-damage, minor-damage, major-damage, destroyed\ndf = df.drop(\"un-classified\", axis=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n#########DATA CREATING OF IMAGES AND LABELS ##########\nfrom torchvision.transforms import functional as TF\n\n\nclass Resize(object):\n    def __init__(self, size):\n        self.size = size  # size should be a tuple (height, width)\n\n    def __call__(self, image, target):\n        orig_width, orig_height = image.size\n        image = TF.resize(image, self.size)\n\n        ratio_width = self.size[0] / orig_width\n        ratio_height = self.size[1] / orig_height\n\n        if \"boxes\" in target:\n            boxes = target[\"boxes\"]\n            boxes[:, [0, 2]] = boxes[:, [0, 2]] * ratio_width\n            boxes[:, [1, 3]] = boxes[:, [1, 3]] * ratio_height\n            target[\"boxes\"] = boxes\n\n        if \"masks\" in target:\n            masks = target[\"masks\"]\n            masks = masks.unsqueeze(1)  # Add channel dimension\n            masks = TF.resize(\n                masks, self.size, interpolation=TF.InterpolationMode.NEAREST\n            )\n            masks = masks.squeeze(1)\n            target[\"masks\"] = masks\n\n        return image, target\n\n\nclass BuildingDataset(Dataset):\n    def __init__(self, df, resize_size=(512, 512)):\n        self.df = df.reset_index(drop=True)\n        self.resize_size = resize_size\n        self.damage_class_to_id = {\n            \"no-damage\": 1,\n            \"minor-damage\": 2,\n            \"major-damage\": 3,\n            \"destroyed\": 4,\n        }\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row.post_image_path\n        label_path = row.post_label_path\n        image_id = torch.tensor([idx])\n\n        with rasterio.open(img_path) as src:\n            img_array = src.read()\n            if img_array.shape[0] >= 3:\n                img_array = img_array[:3, :, :]\n            else:\n                img_array = np.repeat(img_array, 3, axis=0)\n\n            img_array = np.transpose(img_array, (1, 2, 0)).astype(np.uint8)\n            img = Image.fromarray(img_array)\n\n        width, height = img.size\n\n        with open(label_path, \"r\") as f:\n            annotations = json.load(f)\n\n        boxes = []\n        labels = []\n        masks = []\n        annotations = annotations[\"features\"][\"xy\"]\n\n        for annotation in annotations:\n            properties = annotation[\"properties\"]\n            subtype = properties[\"subtype\"]\n            damage_label = self.damage_class_to_id.get(subtype, 0)\n\n            polygon_wkt = annotation[\"wkt\"]\n            polygon = loads(polygon_wkt)\n\n            if not polygon.is_valid:\n                continue\n\n            polygon = self._clip_polygon_to_image(polygon, width, height)\n            if polygon.is_empty:\n                continue\n\n            xmin, ymin, xmax, ymax = polygon.bounds\n            boxes.append([xmin, ymin, xmax, ymax])\n            labels.append(damage_label)\n\n            mask = self._polygon_to_mask(polygon, width, height)\n            masks.append(mask)\n\n        if len(boxes) == 0:\n            target = {\n                \"boxes\": torch.zeros((0, 4), dtype=torch.float32),\n                \"labels\": torch.zeros((0,), dtype=torch.int64),\n                \"masks\": torch.zeros((0, height, width), dtype=torch.uint8),\n                \"image_id\": image_id,\n            }\n        else:\n            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n            labels = torch.as_tensor(labels, dtype=torch.int64)\n            masks = torch.as_tensor(np.stack(masks, axis=0), dtype=torch.uint8)\n\n            target = {\n                \"boxes\": boxes,\n                \"labels\": labels,\n                \"masks\": masks,\n                \"image_id\": image_id,\n            }\n\n        resize_transform = Resize(self.resize_size)\n        img, target = resize_transform(img, target)\n\n        # Use TF.to_tensor instead of F.to_tensor\n        img = TF.to_tensor(img)\n\n        return {\n            \"img\": img,\n            \"target\": target\n        }\n\n    def __len__(self):\n        return len(self.df)\n\n    def _polygon_to_mask(self, polygon, width, height):\n        mask = Image.new(\"L\", (width, height), 0)\n        draw = ImageDraw.Draw(mask)\n\n        if polygon.is_empty:\n            return np.array(mask, dtype=np.uint8)\n\n        if polygon.geom_type == \"Polygon\":\n            if polygon.exterior is not None:\n                x, y = polygon.exterior.coords.xy\n                coords = [(xi, yi) for xi, yi in zip(x, y)]\n                draw.polygon(coords, outline=1, fill=1)\n        elif polygon.geom_type == \"MultiPolygon\":\n            for poly in polygon.geoms:\n                if poly.exterior is not None:\n                    x, y = poly.exterior.coords.xy\n                    coords = [(xi, yi) for xi, yi in zip(x, y)]\n                    draw.polygon(coords, outline=1, fill=1)\n\n        return np.array(mask, dtype=np.uint8)\n\n    def _clip_polygon_to_image(self, polygon, width, height):\n        image_box = box(0, 0, width, height)\n        return polygon.intersection(image_box)\n\n# Instantiate dataset\ntrain_dataset = BuildingDataset(df, resize_size=(128, 128))\n\n\ndef collate_fn(batch):\n    # Extract each component from the batch of dictionaries\n    imgs = [item[\"img\"] for item in batch]\n    targets = [item[\"target\"] for item in batch]\n    return imgs, targets\n\n\n\n########## Create DataLoaders for training  or you can use this for validation data loading\n######### like test,tier1,tier3 or use any of these for training and testing present on my profile\n##########   https://www.kaggle.com/muhammadqasimshabbir/datasets  you can use like following\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=8,\n    collate_fn=collate_fn,\n)\n###############################  Data LOADING IS COMPELTE  ##########################\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"######################  model training  ####################################\ndef get_maskrcnn_model(num_classes=5):\n    # Load a Mask R-CNN model pre-trained on COCO\n    model = maskrcnn_resnet50_fpn(pretrained=True)\n\n    # Replace the bounding box predictor for the correct number of classes\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # Replace the mask predictor for the correct number of classes\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n        in_features_mask, hidden_layer, num_classes\n    )\n\n    return model\n\n\n# Initialize the model\nmodel = get_maskrcnn_model(num_classes=5)\nmodel = model.cuda()  # Move to GPU if available\nmodel.train()  # Set to training mode\n\n# Define an optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    # Training loop\n    for batch_idx, batch in enumerate(train_loader):\n        # Unpack the batch\n        imgs, targets = batch\n\n        # Move images and targets to GPU if available\n        imgs = [img.cuda() for img in imgs]\n        targets = [\n            {k: v.cuda() if torch.is_tensor(v) else v for k, v in t.items()}\n            for t in targets\n        ]\n\n        # Forward pass through the model to compute losses\n        losses_dict = model(imgs, targets)\n        losses = sum(loss for loss in losses_dict.values())\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        # Print training progress every 10 batches\n        if batch_idx % 40 == 0:\n            print(\n                f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}] Loss: {losses.item():.4f}\"\n            )\n\n    # # After each epoch, evaluate on the validation set\n    model.eval()  # Set model to evaluation mode\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#################### Prediction and Submission Creations ############################\n\n\n\n# Test dataset class\nclass TestDataset(Dataset):\n    \"\"\"\n    A PyTorch Dataset class for test images of buildings.\n    This dataset returns a dictionary similar to the training dataset but without targets:\n    {\n        \"img\": Tensor(C,H,W),\n        \"NDVI_mean\": Tensor(1),\n        \"NBR_mean\" : Tensor(1),\n        \"NDMI_mean\": Tensor(1),\n        \"NDWI_mean\": Tensor(1),\n        \"img_id\": <image identifier>\n    }\n    \"\"\"\n\n    def __init__(self, df, resize_size=(512, 512)):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): A dataframe containing test image paths and their metadata.\n                               It should have columns like 'post_image_path', 'id', and the vegetation indices.\n            resize_size (tuple): The (height, width) to resize images to.\n        \"\"\"\n        self.df = df.reset_index(drop=True)\n        self.resize_size = resize_size\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Loads and preprocesses an image and its associated metadata from the test dataset.\n\n        Args:\n            idx (int): The index of the image in the dataset.\n\n        Returns:\n            dict: {\n                \"img\": preprocessed image tensor,\n                \"NDVI_mean\": mean NDVI value (float tensor),\n                \"NBR_mean\": mean NBR value (float tensor),\n                \"NDMI_mean\": mean NDMI value (float tensor),\n                \"NDWI_mean\": mean NDWI value (float tensor),\n                \"img_id\": unique identifier for the image\n            }\n        \"\"\"\n        row = self.df.iloc[idx]\n        img_path = row.post_image_path\n        img_id = row.id\n\n\n        # Load image with rasterio\n        with rasterio.open(img_path) as src:\n            img_array = src.read()  # shape: (C, H, W)\n\n            # Ensure at least 3 channels (R,G,B)\n            if img_array.shape[0] >= 3:\n                img_array = img_array[:3, :, :]\n            else:\n                # If fewer than 3 channels, replicate to make it appear like an RGB image\n                img_array = np.repeat(img_array, 3, axis=0)\n\n            # Convert to H x W x C and uint8\n            img_array = np.transpose(img_array, (1, 2, 0)).astype(np.uint8)\n\n            # Convert to PIL Image\n            img = Image.fromarray(img_array)\n\n        # Resize and convert to tensor\n        img = F.resize(img, self.resize_size)\n        img = F.to_tensor(img)\n\n        return {\n            \"img\": img,\n            \"img_id\": img_id\n        }\n\n    def __len__(self):\n        return len(self.df)\n\n\ndef test_collate_fn(batch):\n    \"\"\"\n    Collate function for the test dataset, similar to the training collate function,\n    but excluding targets. It returns:\n    (imgs, NDVI_means, NBR_means, NDMI_means, NDWI_means, img_ids)\n\n    Args:\n        batch (list): A list of samples from the TestDataset.\n\n    Returns:\n        tuple: (imgs, NDVI_means, NBR_means, NDMI_means, NDWI_means, img_ids)\n    \"\"\"\n    imgs = [item[\"img\"] for item in batch]\n    img_ids = [item[\"img_id\"] for item in batch]\n\n    return imgs,img_ids\n\n\n\n# Create the test dataset and DataLoader\ntest_dataset = TestDataset(test_df, resize_size=(128, 128))\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=8,\n    collate_fn=test_collate_fn,\n)\n\ndamage_class_to_id = {\n    \"no-damage\": 1,\n    \"minor-damage\": 2,\n    \"major-damage\": 3,\n    \"destroyed\": 4,\n}\nid_to_damage_class = {v: k for k, v in damage_class_to_id.items()}\n\n\ndef predict_and_count(model, data_loader, device, score_threshold=0.5):\n    \"\"\"\n    Run inference with the model on the test data and count the number of buildings per class per image.\n    Now we also have vegetation indices and img_ids for reference, but they are not directly used in counting.\n\n    Args:\n        model (nn.Module): The trained Mask R-CNN model.\n        data_loader (DataLoader): DataLoader for the test dataset.\n        device (torch.device): The device to run inference on (CPU or GPU).\n        score_threshold (float): Minimum score threshold for counting a prediction.\n\n    Returns:\n        list of dict: A list of dictionaries, each containing:\n            {\n              \"img_id\": <image identifier>,\n              \"counts\": {\n                \"no-damage\": int,\n                \"minor-damage\": int,\n                \"major-damage\": int,\n                \"destroyed\": int\n              }\n            }\n    \"\"\"\n    model.eval()\n    image_counts = []\n\n    with torch.no_grad():\n        for imgs,  img_ids in tqdm(\n            data_loader, desc=\"Inference\"\n        ):\n            # Move images to the device\n            imgs = [img.to(device) for img in imgs]\n\n            # Run the model\n            outputs = model(imgs)\n\n            for i, output in enumerate(outputs):\n                img_id = img_ids[i]\n\n                # Filter predictions by score threshold\n                scores = output[\"scores\"].cpu()\n                keep = scores >= score_threshold\n                labels = output[\"labels\"][keep].cpu().numpy()\n\n                # Count instances per class\n                counts = {class_name: 0 for class_name in damage_class_to_id.keys()}\n                for label in labels:\n                    class_name = id_to_damage_class.get(label, \"unknown\")\n                    if class_name in counts:\n                        counts[class_name] += 1\n\n                # Store the results for this image\n                image_counts.append({\"img_id\": img_id, \"counts\": counts})\n\n    return image_counts\n\n\ndevice = \"cuda\"\nmodel.eval()\n\n\nprint(\"========= Prediction stared ================\")\npredictions = predict_and_count(model, test_loader, device, score_threshold=0.5)\nprint(\"============== completed  =================\")\n# Create sub file\nrows = []\n\n# Loop over each image's counts\nfor entry in predictions:\n    img_id = entry[\"img_id\"]\n    counts = entry[\"counts\"]\n\n    # For each damage class, create a row\n    for damage_class, count in counts.items():\n        # Format the damage class to replace hyphens with underscores\n        damage_class_formatted = damage_class.replace(\"-\", \"_\")\n        # Construct the 'id' as per your required format\n        row_id = f\"{img_id}_X_{damage_class_formatted}\"\n        # Append the row to the list\n        rows.append({\"id\": row_id, \"target\": count})\n\n# Create the DataFrame\nsub_df = pd.DataFrame(rows)\n\n# Sort the DataFrame by 'id'\nsub_df = sub_df.sort_values(\"id\").reset_index(drop=True)\n\nsub_df\nsub_df.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}